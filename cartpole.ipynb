{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvzIRtQG+g7lsn15wtvZWZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParlitsisG/Cart_pole_Dqn/blob/main/cartpole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jJtLYdtoE96",
        "outputId": "de28f445-8dd8-4f69-e846-297b362a1afe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.9/dist-packages (0.25.2)\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ray[rllib]==2.2.0\n",
            "  Downloading ray-2.2.0-cp39-cp39-manylinux2014_x86_64.whl (57.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (1.22.4)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (1.51.3)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (3.19.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (2.25.1)\n",
            "Collecting frozenlist\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting virtualenv>=20.0.24\n",
            "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (1.0.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (6.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (22.2.0)\n",
            "Collecting aiosignal\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (4.3.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (8.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (3.9.0)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich\n",
            "  Downloading rich-13.3.2-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.7/238.7 KB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (1.4.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (0.8.10)\n",
            "Collecting gym\n",
            "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.2/626.2 KB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (0.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (1.10.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (0.1.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (0.19.3)\n",
            "Requirement already satisfied: matplotlib!=3.4.3 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]==2.2.0) (3.5.3)\n",
            "Collecting lz4\n",
            "  Downloading lz4-4.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.9/dist-packages (from gym) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.10.0->gym) (3.15.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (4.39.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.4.3->ray[rllib]==2.2.0) (23.0)\n",
            "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.9/dist-packages (from virtualenv>=20.0.24->ray[rllib]==2.2.0) (3.1.1)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->ray[rllib]==2.2.0) (0.19.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->ray[rllib]==2.2.0) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->ray[rllib]==2.2.0) (1.26.15)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->ray[rllib]==2.2.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->ray[rllib]==2.2.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->ray[rllib]==2.2.0) (2.10)\n",
            "Collecting pygments<3.0.0,>=2.13.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown-it-py<3.0.0,>=2.2.0\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->ray[rllib]==2.2.0) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->ray[rllib]==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->ray[rllib]==2.2.0) (2023.2.28)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->ray[rllib]==2.2.0) (3.0)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib!=3.4.3->ray[rllib]==2.2.0) (1.15.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.23.1-py3-none-any.whl size=701374 sha256=da72866754ac5fd9ec44e57dfc85a39a224837be4b3ea02f7992351bcf4013d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/be/7e/92a54668db96883e38ce60a9249dc55de7cd6eee49e7311940\n",
            "Successfully built gym\n",
            "Installing collected packages: distlib, virtualenv, tensorboardX, pygments, pygame, mdurl, lz4, frozenlist, markdown-it-py, gym, aiosignal, rich, ray\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiosignal-1.3.1 distlib-0.3.6 frozenlist-1.3.3 gym-0.23.1 lz4-4.3.2 markdown-it-py-2.2.0 mdurl-0.1.2 pygame-2.3.0 pygments-2.14.0 ray-2.2.0 rich-13.3.2 tensorboardX-2.6 virtualenv-20.21.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gym pygame ray[rllib]==2.2.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from ray.rllib.algorithms.dqn import DQNConfig"
      ],
      "metadata": {
        "id": "xw2Ie8DioHJX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomEnv(gym.Env):\n",
        "    def __init__(self, env_config: dict):\n",
        "        \n",
        "        # Construct & Init Environment\n",
        "        self._env = gym.make('CartPole-v1')\n",
        "\n",
        "        # Define Action Space: 2 Discrete Actions for cartpole\n",
        "        self.action_space = gym.spaces.Discrete(2)\n",
        "\n",
        "        # Define State (Observation) Space: A Continuous State Space represented by a vector of size (4,)\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "             low=np.array([-4.8, -np.inf, -0.42, -np.inf]),\n",
        "            high=np.array([4.8, np.inf, 0.42, np.inf]),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "    # Reset Environment & Init Episode\n",
        "    def reset(self):\n",
        "        observation = self._env.reset()\n",
        "        return observation\n",
        "\n",
        "    def step(self, action):\n",
        "        observation, reward, done, info = self._env.step(action)\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def render(self, mode: str or None = None):\n",
        "        self._env.render()"
      ],
      "metadata": {
        "id": "m3_fIf_AoJp1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = DQNConfig()\n",
        "config.num_steps_sampled_before_learning_starts = 1000\n",
        "config.train_batch_size = 64\n",
        "config.replay_buffer_config.update({\n",
        "    'capacity': 50000\n",
        "})\n",
        "# Pause episode and train\n",
        "config.batch_mode = 'truncate_episodes'\n",
        "\n",
        "# Disabling Dueling Feature\n",
        "config.dueling = False  # later try with True\n",
        "\n",
        "# Setting Epsilon\n",
        "config.exploration_config.update({\n",
        "    \"initial_epsilon\": 0.5,\n",
        "    \"final_epsilon\": 0.01,\n",
        "    \"epsilon_timesteps\": 1000,\n",
        "})\n",
        "\n",
        "# 1 Step per training\n",
        "# config.rollout_fragment_length = 1\n",
        "\n",
        "# Set seed to constant value to reproduce results\n",
        "config.seed = 0\n",
        "\n",
        "# Gamma is the discount factor in bellman equation\n",
        "config.gamma = 0.99\n",
        "\n",
        "# Set learning rate of neural network\n",
        "config.lr = 0.0005\n",
        "\n",
        "# Enable gpu\n",
        "config.num_gpus = 1"
      ],
      "metadata": {
        "id": "M0kUeM3WpzxV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "agent = config.framework(\"tf\").environment(env=CustomEnv, env_config={}).build()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VonHCtkEoJu1",
        "outputId": "85a7a5c4-d605-4192-bb13-9ac835b2522b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-15 17:04:07,971\tINFO worker.py:1538 -- Started a local Ray instance.\n",
            "2023-03-15 17:04:09,839\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "2023-03-15 17:04:17,164\tINFO trainable.py:172 -- Trainable.setup took 11.825 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
            "2023-03-15 17:04:17,166\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YTWr1BLm1rZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(agent, eval_env, eval_episodes):\n",
        "    total_rewards = 0.0\n",
        "\n",
        "    for _ in range(eval_episodes):\n",
        "        done = False\n",
        "        observation = eval_env.reset()\n",
        "\n",
        "        while not done:\n",
        "            action = agent.compute_single_action(observation=observation)\n",
        "            observation, reward, done, _ = eval_env.step(action)\n",
        "            total_rewards += reward\n",
        "\n",
        "    return total_rewards/eval_episodes"
      ],
      "metadata": {
        "id": "0FWulBMfqEL1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps = 1000\n",
        "eval_env = CustomEnv(env_config={})\n",
        "eval_episodes = 5\n",
        "\n",
        "\n",
        "for i in range(num_steps):\n",
        "    agent.train()\n",
        "\n",
        "    if i % 1 == 0:\n",
        "        average_rewards = evaluate(agent, eval_env, eval_episodes)\n",
        "        print('i =', i, ', average rewards =', average_rewards)\n"
      ],
      "metadata": {
        "id": "oAzMqpF7qEOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35024d1d-f28b-489b-b789-76ac77a58653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-15 17:07:05,595\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0 , average rewards = 97.6\n",
            "i = 1 , average rewards = 15.4\n",
            "i = 2 , average rewards = 24.0\n",
            "i = 3 , average rewards = 69.2\n",
            "i = 4 , average rewards = 97.4\n",
            "i = 5 , average rewards = 154.4\n",
            "i = 6 , average rewards = 135.4\n",
            "i = 7 , average rewards = 272.6\n",
            "i = 8 , average rewards = 240.8\n",
            "i = 9 , average rewards = 203.8\n",
            "i = 10 , average rewards = 161.4\n",
            "i = 11 , average rewards = 115.2\n",
            "i = 12 , average rewards = 128.4\n",
            "i = 13 , average rewards = 266.4\n",
            "i = 14 , average rewards = 99.8\n",
            "i = 15 , average rewards = 93.0\n",
            "i = 16 , average rewards = 145.0\n",
            "i = 17 , average rewards = 107.4\n",
            "i = 18 , average rewards = 146.2\n",
            "i = 19 , average rewards = 125.8\n",
            "i = 20 , average rewards = 203.8\n",
            "i = 21 , average rewards = 301.8\n",
            "i = 22 , average rewards = 98.0\n",
            "i = 23 , average rewards = 142.6\n",
            "i = 24 , average rewards = 189.8\n",
            "i = 25 , average rewards = 145.4\n",
            "i = 26 , average rewards = 115.8\n",
            "i = 27 , average rewards = 248.8\n",
            "i = 28 , average rewards = 200.6\n",
            "i = 29 , average rewards = 193.0\n",
            "i = 30 , average rewards = 150.6\n",
            "i = 31 , average rewards = 289.6\n",
            "i = 32 , average rewards = 167.0\n",
            "i = 33 , average rewards = 288.6\n",
            "i = 34 , average rewards = 252.6\n",
            "i = 35 , average rewards = 111.6\n",
            "i = 36 , average rewards = 418.6\n",
            "i = 37 , average rewards = 344.4\n",
            "i = 38 , average rewards = 470.8\n",
            "i = 39 , average rewards = 298.0\n",
            "i = 40 , average rewards = 259.2\n",
            "i = 41 , average rewards = 145.2\n",
            "i = 42 , average rewards = 94.6\n",
            "i = 43 , average rewards = 164.8\n",
            "i = 44 , average rewards = 167.6\n",
            "i = 45 , average rewards = 268.6\n",
            "i = 46 , average rewards = 500.0\n",
            "i = 47 , average rewards = 183.2\n",
            "i = 48 , average rewards = 463.6\n",
            "i = 49 , average rewards = 184.6\n",
            "i = 50 , average rewards = 500.0\n",
            "i = 51 , average rewards = 500.0\n",
            "i = 52 , average rewards = 500.0\n",
            "i = 53 , average rewards = 361.2\n",
            "i = 54 , average rewards = 246.0\n",
            "i = 55 , average rewards = 290.6\n",
            "i = 56 , average rewards = 500.0\n",
            "i = 57 , average rewards = 381.0\n",
            "i = 58 , average rewards = 500.0\n",
            "i = 59 , average rewards = 500.0\n",
            "i = 60 , average rewards = 174.4\n",
            "i = 61 , average rewards = 158.0\n",
            "i = 62 , average rewards = 393.0\n",
            "i = 63 , average rewards = 431.6\n",
            "i = 64 , average rewards = 500.0\n",
            "i = 65 , average rewards = 500.0\n",
            "i = 66 , average rewards = 500.0\n",
            "i = 67 , average rewards = 485.8\n",
            "i = 68 , average rewards = 184.8\n",
            "i = 69 , average rewards = 49.8\n",
            "i = 70 , average rewards = 500.0\n",
            "i = 71 , average rewards = 500.0\n",
            "i = 72 , average rewards = 192.6\n",
            "i = 73 , average rewards = 130.8\n",
            "i = 74 , average rewards = 455.0\n",
            "i = 75 , average rewards = 334.6\n",
            "i = 76 , average rewards = 500.0\n",
            "i = 77 , average rewards = 500.0\n",
            "i = 78 , average rewards = 118.2\n",
            "i = 79 , average rewards = 136.8\n",
            "i = 80 , average rewards = 152.4\n",
            "i = 81 , average rewards = 106.6\n",
            "i = 82 , average rewards = 107.2\n",
            "i = 83 , average rewards = 500.0\n",
            "i = 84 , average rewards = 500.0\n",
            "i = 85 , average rewards = 500.0\n",
            "i = 86 , average rewards = 500.0\n",
            "i = 87 , average rewards = 500.0\n",
            "i = 88 , average rewards = 138.6\n",
            "i = 89 , average rewards = 500.0\n",
            "i = 90 , average rewards = 225.2\n",
            "i = 91 , average rewards = 497.4\n",
            "i = 92 , average rewards = 193.0\n",
            "i = 93 , average rewards = 500.0\n",
            "i = 94 , average rewards = 500.0\n",
            "i = 95 , average rewards = 500.0\n",
            "i = 96 , average rewards = 500.0\n",
            "i = 97 , average rewards = 500.0\n",
            "i = 98 , average rewards = 500.0\n",
            "i = 99 , average rewards = 500.0\n",
            "i = 100 , average rewards = 500.0\n",
            "i = 101 , average rewards = 500.0\n",
            "i = 102 , average rewards = 500.0\n",
            "i = 103 , average rewards = 500.0\n",
            "i = 104 , average rewards = 435.4\n",
            "i = 105 , average rewards = 500.0\n",
            "i = 106 , average rewards = 498.6\n",
            "i = 107 , average rewards = 500.0\n",
            "i = 108 , average rewards = 500.0\n",
            "i = 109 , average rewards = 500.0\n",
            "i = 110 , average rewards = 500.0\n",
            "i = 111 , average rewards = 500.0\n",
            "i = 112 , average rewards = 500.0\n",
            "i = 113 , average rewards = 500.0\n",
            "i = 114 , average rewards = 420.8\n",
            "i = 115 , average rewards = 500.0\n",
            "i = 116 , average rewards = 500.0\n",
            "i = 117 , average rewards = 407.2\n",
            "i = 118 , average rewards = 500.0\n",
            "i = 119 , average rewards = 376.0\n",
            "i = 120 , average rewards = 227.4\n",
            "i = 121 , average rewards = 500.0\n",
            "i = 122 , average rewards = 282.0\n",
            "i = 123 , average rewards = 478.8\n",
            "i = 124 , average rewards = 200.0\n",
            "i = 125 , average rewards = 478.0\n",
            "i = 126 , average rewards = 500.0\n",
            "i = 127 , average rewards = 441.2\n",
            "i = 128 , average rewards = 500.0\n",
            "i = 129 , average rewards = 80.6\n",
            "i = 130 , average rewards = 500.0\n",
            "i = 131 , average rewards = 147.0\n",
            "i = 132 , average rewards = 500.0\n",
            "i = 133 , average rewards = 136.8\n",
            "i = 134 , average rewards = 259.0\n",
            "i = 135 , average rewards = 500.0\n",
            "i = 136 , average rewards = 477.4\n",
            "i = 137 , average rewards = 434.8\n",
            "i = 138 , average rewards = 500.0\n",
            "i = 139 , average rewards = 108.6\n",
            "i = 140 , average rewards = 207.8\n",
            "i = 141 , average rewards = 500.0\n",
            "i = 142 , average rewards = 500.0\n",
            "i = 143 , average rewards = 500.0\n",
            "i = 144 , average rewards = 500.0\n",
            "i = 145 , average rewards = 500.0\n",
            "i = 146 , average rewards = 500.0\n",
            "i = 147 , average rewards = 500.0\n",
            "i = 148 , average rewards = 257.8\n",
            "i = 149 , average rewards = 500.0\n",
            "i = 150 , average rewards = 500.0\n",
            "i = 151 , average rewards = 500.0\n",
            "i = 152 , average rewards = 177.0\n",
            "i = 153 , average rewards = 500.0\n",
            "i = 154 , average rewards = 137.2\n",
            "i = 155 , average rewards = 500.0\n",
            "i = 156 , average rewards = 500.0\n",
            "i = 157 , average rewards = 500.0\n",
            "i = 158 , average rewards = 500.0\n",
            "i = 159 , average rewards = 158.0\n",
            "i = 160 , average rewards = 134.6\n",
            "i = 161 , average rewards = 500.0\n",
            "i = 162 , average rewards = 500.0\n",
            "i = 163 , average rewards = 500.0\n",
            "i = 164 , average rewards = 500.0\n",
            "i = 165 , average rewards = 500.0\n",
            "i = 166 , average rewards = 500.0\n",
            "i = 167 , average rewards = 500.0\n",
            "i = 168 , average rewards = 500.0\n",
            "i = 169 , average rewards = 500.0\n",
            "i = 170 , average rewards = 500.0\n",
            "i = 171 , average rewards = 402.0\n",
            "i = 172 , average rewards = 500.0\n",
            "i = 173 , average rewards = 181.0\n",
            "i = 174 , average rewards = 163.8\n",
            "i = 175 , average rewards = 349.2\n",
            "i = 176 , average rewards = 500.0\n",
            "i = 177 , average rewards = 429.8\n",
            "i = 178 , average rewards = 500.0\n",
            "i = 179 , average rewards = 500.0\n",
            "i = 180 , average rewards = 464.2\n",
            "i = 181 , average rewards = 329.8\n",
            "i = 182 , average rewards = 500.0\n",
            "i = 183 , average rewards = 218.2\n",
            "i = 184 , average rewards = 500.0\n",
            "i = 185 , average rewards = 131.6\n",
            "i = 186 , average rewards = 100.8\n",
            "i = 187 , average rewards = 437.0\n",
            "i = 188 , average rewards = 133.8\n",
            "i = 189 , average rewards = 500.0\n",
            "i = 190 , average rewards = 500.0\n",
            "i = 191 , average rewards = 500.0\n",
            "i = 192 , average rewards = 402.6\n",
            "i = 193 , average rewards = 478.6\n",
            "i = 194 , average rewards = 487.6\n",
            "i = 195 , average rewards = 269.0\n",
            "i = 196 , average rewards = 211.6\n",
            "i = 197 , average rewards = 500.0\n",
            "i = 198 , average rewards = 500.0\n",
            "i = 199 , average rewards = 500.0\n",
            "i = 200 , average rewards = 500.0\n",
            "i = 201 , average rewards = 500.0\n",
            "i = 202 , average rewards = 500.0\n",
            "i = 203 , average rewards = 500.0\n",
            "i = 204 , average rewards = 500.0\n",
            "i = 205 , average rewards = 500.0\n",
            "i = 206 , average rewards = 500.0\n",
            "i = 207 , average rewards = 500.0\n",
            "i = 208 , average rewards = 500.0\n",
            "i = 209 , average rewards = 457.4\n",
            "i = 210 , average rewards = 500.0\n",
            "i = 211 , average rewards = 500.0\n",
            "i = 212 , average rewards = 500.0\n",
            "i = 213 , average rewards = 297.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eVPacUNw1s4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gLLAYfKC1-9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jD_uYlXu1_Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IZWfYKFG1_L8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}